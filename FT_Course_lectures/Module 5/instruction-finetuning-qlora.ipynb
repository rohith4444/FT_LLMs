{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28506e0e-b778-4803-84b1-4c859d2741fd",
   "metadata": {},
   "source": [
    "# Instruction Finetuning using QLoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ba5b8-af16-438d-b3f3-709b65f6ac96",
   "metadata": {},
   "source": [
    "In this notebook, we will look into how to perform instruction finetuning using QLoRA PEFT method. The task is to perform Supervised finetuning (SFT) of CodeLlama for function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b098e055-a939-4da7-879e-85849982cdcb",
   "metadata": {},
   "source": [
    "Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d154b8-9996-40fa-ad02-f8f6c26e9567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/sourab/transformers/src/transformers/utils/hub.py:122: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-01-02 12:52:35.746611: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 12:52:35.746660: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 12:52:35.747489: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 12:52:35.753251: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 12:52:36.555887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-02 12:52:38,201] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"]=\"codellama_instruct_finetuning\"\n",
    "\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig, set_seed\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991163c6-29f3-496e-b71c-f4329ec25df1",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b27033-ba17-4c85-986d-9cbef9262497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content'],\n",
      "        num_rows: 101664\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['content'],\n",
      "        num_rows: 11296\n",
      "    })\n",
      "})\n",
      "{'content': '<|im_start|>system\\nYou are a helpful assistant, with no access to external functions.\\nfunctions: []<|im_end|>\\n<|im_start|>user\\nConsider the following equation with the added constraint that x must be a prime number: \\n1 + 1 = x\\nWhat is the value of x?<|im_end|>\\n<|im_start|>assistant\\nThe equation 1 + 1 = x has a solution of x = 2. However, with the added constraint that x must be a prime number, the only solution is x = 2.<|im_end|>\\n<|im_start|>user\\nCan you explain how encryption works?<|im_end|>\\n<|im_start|>assistant\\nEncryption is the process of converting plaintext into ciphertext, which is a scrambled version of the original message. This is done by using a mathematical algorithm and a key to encode the information in a way that can only be decoded with the corresponding key.<|im_end|>\\n<|im_start|>user\\nWhat is the difference between machine learning and deep learning?<|im_end|>\\n<|im_start|>assistant\\nMachine learning is a subset of artificial intelligence where algorithms are developed to learn patterns in data without being explicitly programmed. Deep learning is a type of machine learning that uses neural networks with multiple layers to learn more complex patterns in the data.<|im_end|>\\n<|im_start|>user\\nCan you explain what the Halting Problem is?<|im_end|>\\n<|im_start|>assistant\\nThe Halting Problem is a fundamental problem in computer science that states it is impossible to write a program that can determine if another program will eventually halt or continue running indefinitely. This was proven by mathematician Alan Turing in 1936 and has important implications in the field of computation theory.<|im_end|>\\n<|im_start|>user\\nHow does blockchain technology work?<|im_end|>\\n<|im_start|>assistant\\nBlockchain technology is a distributed database system that allows for secure, transparent and tamper-proof transactions without requiring a central authority. When a new transaction is added to the blockchain, it is validated by a network of computers called nodes, and then added to a block of other transactions. This block is then linked to the previous block in the chain, creating an immutable record of all transactions.<|im_end|>\\n'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"codellama/CodeLlama-13b-Instruct-hf\"\n",
    "dataset_name = \"heegyu/glaive-function-calling-v2-formatted\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "template = \"\"\"{% for message in messages %}\\n{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% if loop.last and add_generation_prompt %}{{'<|im_start|>assistant\\n' }}{% endif %}{% endfor %}\"\"\"\n",
    "tokenizer.chat_template = template\n",
    "\n",
    "def preprocess(samples):\n",
    "    batch = []\n",
    "    for system_prompt, function_desc, conversation in zip(samples[\"system_message\"], samples[\"function_description\"], samples[\"conversations\"]):\n",
    "        try:\n",
    "            function_desc_formatted = json.dumps(json.loads(f\"[{function_desc}]\"), indent=2, sort_keys=True)\n",
    "        except:\n",
    "            function_desc_formatted = f\"[{function_desc}]\"\n",
    "        system_message = {\"role\": \"system\", \"content\": f\"{system_prompt}\\nfunctions: {function_desc_formatted}\"}\n",
    "        conversation.insert(0, system_message)\n",
    "        batch.append(tokenizer.apply_chat_template(conversation, tokenize=False))\n",
    "    return {\"content\": batch}\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "dataset = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "dataset = dataset[\"train\"].train_test_split(0.1)\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c195a3-d50d-4fd7-91b3-46f1eef96e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant with access to the following functions. Use them if required -\n",
      "functions: [{\n",
      "    \"name\": \"analyze_image\",\n",
      "    \"description\": \"Analyze the contents of an image\",\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"image_url\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The URL of the image\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"image_url\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "\n",
      "{\n",
      "    \"name\": \"search_recipe\",\n",
      "    \"description\": \"Search for a recipe\",\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"keywords\": {\n",
      "                \"type\": \"array\",\n",
      "                \"items\": {\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"description\": \"The keywords to search for in the recipe\"\n",
      "            },\n",
      "            \"cuisine\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The cuisine type (e.g. Italian, Mexican)\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"keywords\"\n",
      "        ]\n",
      "    }\n",
      "}]<|im_end|>\n",
      "<|im_start|>user\n",
      "Hi, I have an image and I want to know what's in it. Can you help?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Of course! Please provide the URL of the image.<|im_end|>\n",
      "<|im_start|>user\n",
      "Here it is: www.example.com/myimage.jpg<|im_end|>\n",
      "<|im_start|>function-call\n",
      "{\"name\": \"analyze_image\", \"arguments\": '{\"image_url\": \"www.example.com/myimage.jpg\"}'}<|im_end|>\n",
      "<|im_start|>function-response\n",
      "{\"description\": \"The image contains a group of people standing in front of a historical monument. There are also some trees and a clear blue sky in the background.\"}<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The image contains a group of people standing in front of a historical monument. There are also some trees and a clear blue sky in the background.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][6][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687b73b-4479-4ff4-9ed9-a0df95e9b40a",
   "metadata": {},
   "source": [
    "## Create the PEFT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641dfc0c-448b-49c4-9643-ce457c0c0ed5",
   "metadata": {},
   "source": [
    "### LoRA Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ae0542-2bc4-47da-8c69-bf122794fcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(r=8,\n",
    "                         lora_alpha=16,\n",
    "                         lora_dropout=0.1,\n",
    "                         target_modules=[\"gate_proj\",\"q_proj\",\"lm_head\",\"o_proj\",\"k_proj\",\"embed_tokens\",\"down_proj\",\"up_proj\",\"v_proj\"],\n",
    "                         task_type=TaskType.CAUSAL_LM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d3a351-1122-41ea-993c-7292a7f63fc0",
   "metadata": {},
   "source": [
    "### bitsandbytes 4-bit quantization config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "568be20f-7a4f-4ea5-9655-fcde8a133c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc83f34-1c74-45af-a0a0-d2684a014647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bb52a3879c4c24bcd49965de992e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(32024, 5120)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ChatmlSpecialTokens(str, Enum):\n",
    "    user = \"<|im_start|>user\"\n",
    "    assistant = \"<|im_start|>assistant\"\n",
    "    system = \"<|im_start|>system\"\n",
    "    function_call = \"<|im_start|>function-call\"\n",
    "    function_response = \"<|im_start|>function-response\"\n",
    "    eos_token = \"<|im_end|>\"\n",
    "    bos_token = \"<s>\"\n",
    "    pad_token = \"<pad>\"\n",
    "\n",
    "    @classmethod\n",
    "    def list(cls):\n",
    "        return [c.value for c in cls]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        pad_token=ChatmlSpecialTokens.pad_token.value,\n",
    "        bos_token=ChatmlSpecialTokens.bos_token.value,\n",
    "        eos_token=ChatmlSpecialTokens.eos_token.value,\n",
    "        additional_special_tokens=ChatmlSpecialTokens.list(),\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "tokenizer.chat_template = template\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             device_map=\"auto\",\n",
    "                                             attn_implementation=\"flash_attention_2\")\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c522d17-7bb5-4ae6-87af-28de73f1cb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32024, 5120)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaFlashAttention2(\n",
       "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32024, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8987259-21a6-415d-abcf-7517588b60da",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78c590d-16cb-4edc-9aab-30b8137a2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"codellama_function_calling_instruct\"\n",
    "per_device_train_batch_size = 2\n",
    "per_device_eval_batch_size = 2\n",
    "gradient_accumulation_steps = 4\n",
    "logging_steps = 5\n",
    "learning_rate = 5e-4\n",
    "max_grad_norm = 1.0\n",
    "num_train_epochs=1\n",
    "warmup_ratio = 0.1\n",
    "lr_scheduler_type = \"cosine\"\n",
    "max_seq_length = 2048\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    save_strategy=\"no\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    weight_decay=0.1,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    bf16=True,\n",
    "    report_to=[\"tensorboard\", \"wandb\"],\n",
    "    hub_private_repo=True,\n",
    "    push_to_hub=True,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6ece17-0db8-41a6-98f9-3b2616b5852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/sourab/trl/trl/trainer/sft_trainer.py:282: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    dataset_text_field=\"content\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    peft_config=peft_config,\n",
    "    dataset_kwargs={\n",
    "        \"append_concat_token\": False,\n",
    "        \"add_special_tokens\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546810f1-4dc1-44b6-b2d7-f91aa7758533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msmangrul\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/raid/sourab/temp/wandb/run-20240102_125251-bfvor3cc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/smangrul/codellama_instruct_finetuning/runs/bfvor3cc' target=\"_blank\">genial-sound-2</a></strong> to <a href='https://wandb.ai/smangrul/codellama_instruct_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/smangrul/codellama_instruct_finetuning' target=\"_blank\">https://wandb.ai/smangrul/codellama_instruct_finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/smangrul/codellama_instruct_finetuning/runs/bfvor3cc' target=\"_blank\">https://wandb.ai/smangrul/codellama_instruct_finetuning/runs/bfvor3cc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeLlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3613' max='3613' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3613/3613 14:45:35, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.348400</td>\n",
       "      <td>0.368368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/sourab/peft/src/peft/utils/save_and_load.py:132: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2228a5a0e7df4201908441c2a90ffe2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1704196084.hf-dgx-01.3328095.0:   0%|          | 0.00/4.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20354080ba5476ba5f94df57d200837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a192ae967c44058fd08ff429e01382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1704196370.hf-dgx-01.3355468.0:   0%|          | 0.00/119k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cbfc0c1fd54727a023520e96bfd414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/720M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87e9f120eea48ff9c84d450c54bcbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b002e41c6ba54644a5b7b27a6fc0fe50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4150ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd6c748",
   "metadata": {},
   "source": [
    "## Loading the trained model and getting the predictions of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "        )\n",
    "\n",
    "peft_model_id = \"smangrul/codellama_function_calling_instruct\"\n",
    "device = \"cuda\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             device_map=\"auto\",\n",
    "                                             attn_implementation=\"flash_attention_2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "# model.to(torch.bfloat16)\n",
    "# model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "376f0794-9ff8-462b-aec3-4c4c5e885ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32016 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system \n",
      "You are a helpful assistant with access to the following functions. You do a reasoning step before acting. Use the functions if required -\n",
      "functions: [{\n",
      "    \"name\": \"get_current_location\",\n",
      "    \"description\": \"Returns the current location. ONLY use this if the user has not provided an explicit location in the query.\",\n",
      "    \"parameters\": {}\n",
      "},\n",
      "{\n",
      "    \"name\": \"search\",\n",
      "    \"description\": \"A search engine. \n",
      "    Useful for when you need to answer questions and provide information about real-time updates, current events and latest NEWS.\n",
      "    Useful to answer general knowledge questions and provide information about people, places, companies, facts, historical events, or other subjects.\n",
      "    Input should be a search query.\"\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"search_query\": {\n",
      "                \"type\": \"array\",\n",
      "                \"items\": {\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"description\": \"The search query\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"search_query\"\n",
      "        ]\n",
      "    }\n",
      "},\n",
      "{\n",
      "    \"name\": \"code_analysis\",\n",
      "    \"description\": \"Useful when the user query can be solved by writing Python code. \n",
      "    This function generates high quality Python code and runs it to solve the user query and provide the output.\n",
      "    Useful when user asks queries that can be solved with Python code. \n",
      "    Useful for sorting, generating graphs for data visualization and analysis, solving arthmetic and logical questions, data wrangling and data chrunching tasks for csv files etc.\",\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"text_prompt\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The description of the problem to be solved by writing python code.\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"text_prompt\"\n",
      "        ]\n",
      "    }\n",
      "},\n",
      "{\n",
      "    \"name\": \"analyze_image\",\n",
      "    \"description\": \"Analyze the contents of an image\",\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"image_url\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The URL of the image\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"image_url\"\n",
      "        ]\n",
      "    }\n",
      "},\n",
      "{\n",
      "    \"name\": \"generate_image\",\n",
      "    \"description\": \"generate image based on the given description. \",\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"text_prompt\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The description of the image to be generated\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"text_prompt\"\n",
      "        ]\n",
      "    }\n",
      "}]<|im_end|> \n",
      "<|im_start|>user \n",
      "I want to know about tour packages from India to Maldives.<|im_end|> \n",
      "<|im_start|>function-call \n",
      "{\"name\": \"search\", \"arguments\": '{\"search_query\": [\"tour packages\", \"India\", \"Maldives\"]}'}<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant with access to the following functions. You do a reasoning step before acting. Use the functions if required -\n",
    "functions: [{\n",
    "    \"name\": \"get_current_location\",\n",
    "    \"description\": \"Returns the current location. ONLY use this if the user has not provided an explicit location in the query.\",\n",
    "    \"parameters\": {}\n",
    "},\n",
    "{\n",
    "    \"name\": \"search\",\n",
    "    \"description\": \"A search engine. \n",
    "    Useful for when you need to answer questions and provide information about real-time updates, current events and latest NEWS.\n",
    "    Useful to answer general knowledge questions and provide information about people, places, companies, facts, historical events, or other subjects.\n",
    "    Input should be a search query.\"\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"search_query\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"description\": \"The search query\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"search_query\"\n",
    "        ]\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"name\": \"code_analysis\",\n",
    "    \"description\": \"Useful when the user query can be solved by writing Python code. \n",
    "    This function generates high quality Python code and runs it to solve the user query and provide the output.\n",
    "    Useful when user asks queries that can be solved with Python code. \n",
    "    Useful for sorting, generating graphs for data visualization and analysis, solving arthmetic and logical questions, data wrangling and data chrunching tasks for csv files etc.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"text_prompt\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The description of the problem to be solved by writing python code.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"text_prompt\"\n",
    "        ]\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"name\": \"analyze_image\",\n",
    "    \"description\": \"Analyze the contents of an image\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"image_url\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The URL of the image\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"image_url\"\n",
    "        ]\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"name\": \"generate_image\",\n",
    "    \"description\": \"generate image based on the given description. \",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"text_prompt\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The description of the image to be generated\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"text_prompt\"\n",
    "        ]\n",
    "    }\n",
    "}]\"\"\"\n",
    "\n",
    "# Can you tell me what's in the image www.example.com/myimage.jpg?\n",
    "# Please give me the receipe for kadhai paneer.\n",
    "# Where am I?\n",
    "# Generate an image of Indian festival Sankranthi where children are flying colourful kites on their terrace.\n",
    "# What is the latest news of earthquakes in Japan?\n",
    "# Sort the array [1,7,5,6].\n",
    "# I want to know about tour packages from India to Maldives.\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"I want to know about tour packages from India to Maldives.\"},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
    "inputs = {k: v.to(\"cuda\") for k,v in inputs.items()}\n",
    "with torch.autocast(dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    outputs = model.generate(**inputs, \n",
    "                             max_new_tokens=128, \n",
    "                             do_sample=True, \n",
    "                             top_p=0.95, \n",
    "                             temperature=0.2, \n",
    "                             repetition_penalty=1.0, \n",
    "                             eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b18b2-f718-43b4-aad8-baa4e1d2dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
